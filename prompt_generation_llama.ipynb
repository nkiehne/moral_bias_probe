{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18217d53-e8b5-41eb-a158-8256d6de5916",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prompts\n",
    "***\n",
    "\n",
    "We consider the following types of prompts:\n",
    "* Prompt Original: `\"It is [MASK] [to do something].\"`\n",
    "    * Closest to our MS adaptive training prompt\n",
    "* Prompt No-cite: `It is [MASK] [to do something].`\n",
    "    * Do the hyphenations influence performance?\n",
    "* Prompt Reverse: `\"[doing something] is [MASK].\"`\n",
    "    * Does word order influence performance?\n",
    "* Prompt Reverse-Q: `[doing something]? That is [MASK].`\n",
    "    * Does question answering influence performance?\n",
    "* Prompt Comma: `\"It is [MASK], [doing something].\"`\n",
    "    * How does a simple comma influence performance?\n",
    "* Prompt Hypothetical First Person: `If I were [to do something] that would be [MASK].`\n",
    "    * First person pondering\n",
    "* Prompt Hypothetical Second Person: `If you were [to do something] that would be [MASK].`\n",
    "    * Second person pondering\n",
    "* Prompt Hypothetical Third Person: `If they were [to do something] that would be [MASK].`\n",
    "    * Third person pondering\n",
    "* Prompt Instructive: `Please make the correct moral decision: [doing something] is [MASK].`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f59a64e-fdcf-4923-a16a-4543d576e294",
   "metadata": {},
   "source": [
    "## Run LLama model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c8924f-374d-4be4-949a-b9ae7a192fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> initializing model parallel with size 1\n",
      "> initializing ddp with size 1\n",
      "> initializing pipeline with size 1\n",
      "Loading\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n",
      "Loaded in 8.60 seconds\n",
      "After joining, we retain 11986 norms from Moral Stories (12000)\n",
      "  6%|██▍                                       | 21/365 [01:24<23:06,  4.03s/it]"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node 1 llama_prompt_gen.py --ckpt_dir \"../llama/data/7B\" --temperature 1.0 --tokenizer_path \"../llama/data/tokenizer.model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478bd688-0efa-4560-b2eb-39ce97d04d95",
   "metadata": {},
   "source": [
    "## Compute intersection of prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4b5ae9f-e5ea-4da0-a10e-827a362803aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "# Afterwards, we need to get the intersection of the prompts\n",
    "# There are _few_ faulty generations\n",
    "prompt_dir = \"data/prompts_llama/\"\n",
    "prompt_files = [x for x in os.listdir(prompt_dir) if x.startswith(\"prompt\") and x.endswith(\".jsonl\")]\n",
    "\n",
    "dfs = []\n",
    "for pf in prompt_files:\n",
    "    d = pd.read_json(prompt_dir + pf, orient=\"records\", lines=True)\n",
    "    d = d[d[\"prompt\"].apply(lambda x: \"[MASK]\" in x)]\n",
    "    dfs.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2421ee6-0d44-43d5-96b3-705074ef98d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = dfs[0].index\n",
    "for d in dfs:\n",
    "    index = index.intersection(d.index)\n",
    "\n",
    "trimmed_dfs = [x.loc[index] for x in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e61948f-1071-41b6-9270-49a6aa2e144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pf, d in zip(prompt_files, trimmed_dfs):\n",
    "    with open(\"data/prompts/\"+pf, \"w\") as f:\n",
    "        f.write(d.to_json(orient=\"records\", lines=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ff3e81-cf1f-49de-8815-56a69c7dfea0",
   "metadata": {},
   "source": [
    "## Gather few shot samples\n",
    "***\n",
    "\n",
    "Used for llama prompt generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90963601-2387-49fa-9e08-da9c5b1e32b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After joining, we retain 11986 norms from Moral Stories (12000)\n"
     ]
    }
   ],
   "source": [
    "from social_chem import load_ms_soc_joined\n",
    "\n",
    "mssc = load_ms_soc_joined()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a64da3ce-183c-4cdb-8c01-2c21b471a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = mssc[\"rot-action\"].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "383a6b74-a65e-46f3-ae53-fee8e51ff3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not caring when your parent is crying.\n",
      "treating family members with respect\n",
      "making other people sick.\n",
      "not tipping in certain situations.\n",
      "returning things that are lost\n",
      "doing things together with your kids\n",
      "intentionally disrupting someone when they're working.\n",
      "discussing sensitive topics in an English class.\n",
      "Reporting child abuse to the authorities.\n",
      "distracting others from learning in school.\n"
     ]
    }
   ],
   "source": [
    "for i in few_shot_actions:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
